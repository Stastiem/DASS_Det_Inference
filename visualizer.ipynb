{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import cv2\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython\n",
    "from IPython.display import Image as img\n",
    "from IPython.display import display\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dass_det.models.yolox import YOLOX\n",
    "from dass_det.models.yolo_head import YOLOXHead\n",
    "from dass_det.models.yolo_head_stem import YOLOXHeadStem\n",
    "from dass_det.models.yolo_pafpn import YOLOPAFPN\n",
    "\n",
    "from dass_det.data.data_augment import ValTransform\n",
    "\n",
    "from dass_det.utils import (\n",
    "    postprocess,\n",
    "    vis\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Parameters Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path  = \"weights/sample_model.pth\" # None # \"weights/...\"\n",
    "model_size  = \"xs\" # \"xl\"\n",
    "model_mode  = 0    # 1 for only face, 2 for only body\n",
    "\n",
    "nms_thold   = 0.4\n",
    "conf_thold  = 0.65\n",
    "resize_size = (1024, 1024)\n",
    "\n",
    "image_path  = \"/datasets/COMICS/raw_page_images/3665/12.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ValTransform()\n",
    "\n",
    "def predict_and_draw(model, imgs, path, scale, sizes, conf_thold, nms_thold):\n",
    "    img_cu = torch.Tensor(imgs).unsqueeze(0).cuda()\n",
    "    # print(\"Predicting:\", path)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        face_preds, body_preds = model(img_cu, mode=0)\n",
    "        face_preds = postprocess(face_preds, 1, conf_thold, nms_thold)[0]\n",
    "        body_preds = postprocess(body_preds, 1, conf_thold, nms_thold)[0]\n",
    "\n",
    "    del img_cu\n",
    "    \n",
    "    if face_preds is not None: \n",
    "        len_faces = face_preds.shape[0]\n",
    "    else:\n",
    "        len_faces = 0\n",
    "    \n",
    "    if body_preds is not None:\n",
    "        len_bodies = body_preds.shape[0]\n",
    "    else:\n",
    "        len_bodies = 0\n",
    "    \n",
    "    if face_preds is not None and body_preds is not None:\n",
    "        preds = torch.cat([face_preds, body_preds], dim=0)\n",
    "    elif face_preds is not None:\n",
    "        preds = face_preds\n",
    "    elif body_preds is not None:\n",
    "        preds = body_preds\n",
    "    else:\n",
    "        print(\"No faces or bodies are found!\")\n",
    "        if type(path) == str:\n",
    "            p_img = cv2.imread(path)[:,:,::-1]\n",
    "        else:\n",
    "            p_img = cv2.imread(os.path.join(path[1], path[2] + \".jpg\"))[:,:,::-1]\n",
    "        plt.imshow(p_img)\n",
    "        return\n",
    "\n",
    "    classes = torch.cat([torch.zeros(len_faces), torch.ones(len_bodies)])\n",
    "\n",
    "    preds[:,:4] /= scale\n",
    "    preds[:,0]  = torch.max(preds[:,0], torch.zeros(preds.shape[0]).cuda())\n",
    "    preds[:,1]  = torch.max(preds[:,1], torch.zeros(preds.shape[0]).cuda())\n",
    "    preds[:,2]  = torch.min(preds[:,2], torch.zeros(preds.shape[0]).fill_(sizes[1]).cuda())\n",
    "    preds[:,3]  = torch.min(preds[:,3], torch.zeros(preds.shape[0]).fill_(sizes[0]).cuda())\n",
    "    scores      = preds[:,4]\n",
    "\n",
    "    if type(path) == str:\n",
    "        p_img = cv2.imread(path)[:,:,::-1]\n",
    "    else:\n",
    "        p_img = cv2.imread(os.path.join(path[1], path[2] + \".jpg\"))[:,:,::-1]\n",
    "    \n",
    "    display(Image.fromarray(vis(copy.deepcopy(p_img), preds[:,:4], scores, classes, conf=0.0, class_names=[\"Face\", \"Body\"])))\n",
    "    \n",
    "    del face_preds, body_preds, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model_path is not None\n",
    "assert model_size in [\"xs\", \"xl\"]\n",
    "assert model_mode in [0, 1, 2]\n",
    "\n",
    "if model_size == \"xs\":\n",
    "    depth, width = 0.33, 0.375\n",
    "elif model_size == \"xl\":\n",
    "    depth, width = 1.33, 1.25\n",
    "\n",
    "model = YOLOX(backbone=YOLOPAFPN(depth=depth, width=width),\n",
    "              head_stem=YOLOXHeadStem(width=width),\n",
    "              face_head=YOLOXHead(1, width=width),\n",
    "              body_head=YOLOXHead(1, width=width))\n",
    "\n",
    "d = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "if \"teacher_model\" in d.keys():\n",
    "    model.load_state_dict(d[\"teacher_model\"])\n",
    "else:\n",
    "    model.load_state_dict(d[\"model\"])\n",
    "model = model.eval().cuda()\n",
    "\n",
    "del d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = cv2.imread(image_path)\n",
    "h, w, c = imgs.shape\n",
    "\n",
    "imgs, labels = transform(imgs, None, resize_size)\n",
    "scale = min(resize_size[0] / h, resize_size[1] / w)\n",
    "\n",
    "predict_and_draw(model, copy.deepcopy(imgs), image_path, scale, [h, w], conf_thold, nms_thold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolox",
   "language": "python",
   "name": "yolox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
